<!DOCTYPE html>





<html class="theme-next pisces use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="generator" content="Hexo 3.9.0">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.3.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.3.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.3.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '7.3.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    search: {
      root: '/',
      path: ''
    },
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    }
  };
</script>

  <meta name="description" content="深度学习飞速发展过程中，人们发现原有的处理器无法满足神经网络这种特定的大量计算，大量的开始针对这一应用进行专用芯片的设计。谷歌的张量处理单元（Tensor Processing Unit，后文简称TPU）是完成较早，具有代表性的一类设计，基于脉动阵列设计的矩阵计算加速单元，可以很好的加速神经网络的计算。本系列文章将利用公开的TPU V1相关资料，对其进行一定的简化、推测和修改，来实际编写一个简单">
<meta name="keywords" content="Tensor Processing Unit,Architecture,Instruction Level Parallelism,Data Parallelism,VLIW,SMID,Vector Architecture">
<meta property="og:type" content="article">
<meta property="og:title" content="TPU中的指令并行和数据并行">
<meta property="og:url" content="http://cea-wind.github.io/2019/08/03/TPU_c4/index.html">
<meta property="og:site_name" content="SEAWIND">
<meta property="og:description" content="深度学习飞速发展过程中，人们发现原有的处理器无法满足神经网络这种特定的大量计算，大量的开始针对这一应用进行专用芯片的设计。谷歌的张量处理单元（Tensor Processing Unit，后文简称TPU）是完成较早，具有代表性的一类设计，基于脉动阵列设计的矩阵计算加速单元，可以很好的加速神经网络的计算。本系列文章将利用公开的TPU V1相关资料，对其进行一定的简化、推测和修改，来实际编写一个简单">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://raw.githubusercontent.com/cea-wind/blogs_pictures/master/img20190803171553.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cea-wind/blogs_pictures/master/img20190803171640.png">
<meta property="og:updated_time" content="2019-08-03T09:47:48.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="TPU中的指令并行和数据并行">
<meta name="twitter:description" content="深度学习飞速发展过程中，人们发现原有的处理器无法满足神经网络这种特定的大量计算，大量的开始针对这一应用进行专用芯片的设计。谷歌的张量处理单元（Tensor Processing Unit，后文简称TPU）是完成较早，具有代表性的一类设计，基于脉动阵列设计的矩阵计算加速单元，可以很好的加速神经网络的计算。本系列文章将利用公开的TPU V1相关资料，对其进行一定的简化、推测和修改，来实际编写一个简单">
<meta name="twitter:image" content="https://raw.githubusercontent.com/cea-wind/blogs_pictures/master/img20190803171553.png">
  <link rel="canonical" href="http://cea-wind.github.io/2019/08/03/TPU_c4/">


<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>TPU中的指令并行和数据并行 | SEAWIND</title>
  








  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">SEAWIND</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
    <ul id="menu" class="menu">
        
        
        
          
          <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">
      
    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
    </ul>
</nav>

</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://cea-wind.github.io/2019/08/03/TPU_c4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SEAWIND">
    </span>
      <header class="post-header">

        
          <h2 class="post-title" itemprop="name headline">TPU中的指令并行和数据并行

              
            
          </h2>
        

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-08-03 01:56:17 / 修改时间：17:47:48" itemprop="dateCreated datePublished" datetime="2019-08-03T01:56:17+08:00">2019-08-03</time>
            </span>
          
            

            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/TPU/" itemprop="url" rel="index"><span itemprop="name">TPU</span></a></span>

                
                
              
            </span>
          

          <br>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <blockquote>
<p>深度学习飞速发展过程中，人们发现原有的处理器无法满足神经网络这种特定的大量计算，大量的开始针对这一应用进行专用芯片的设计。谷歌的张量处理单元（Tensor Processing Unit，后文简称TPU）是完成较早，具有代表性的一类设计，基于脉动阵列设计的矩阵计算加速单元，可以很好的加速神经网络的计算。本系列文章将利用公开的TPU V1相关资料，对其进行一定的简化、推测和修改，来实际编写一个简单版本的谷歌TPU，以更确切的了解TPU的优势和局限性。</p>
</blockquote>
<p>TPU V1定义了一套自己的指令集，虽然在介绍处理器时，往往会先谈指令集架构，但此处却把它放到了最后，这主要基于两个原因；其一在于个人的对处理器不太了解，这也是主要原因，其二在于公开资料中并没有TPU指令集的细节和TPU微架构的描述。从数据流和计算单元出发对TPU进行分析固然容易很多，但如果想理解TPU的设计思想，依旧需要回到其架构设计上进行分析。这一部分内容有些超出了我现有的能力，不当之处还请多多指正。</p>
<p>本文主要探讨从架构设计上看，TPU时如何做高性能和高效能的设计。高性能的多来自于并行，因此本文分别讨论了指令并行和数据并行的设计方法。由于论文中并未描述TPU指令集的具体设计，除特别说明外，本文关于TPU指令集的探讨均为推测；另外，SimpleTPU的指令设计并不系统/完整，此处仅阐明设计中的几种基本思想。</p>
<h1 id="1-TPU的指令集"><a href="#1-TPU的指令集" class="headerlink" title="1. TPU的指令集"></a>1. TPU的指令集</h1><p>TPU的指令集采用CISC设计，共计有十多条指令，主要的五条指令包括</p>
<ul>
<li>Read_Host_Memory 将数据从CPU的内存中读取到TPU的Unified Buffer上</li>
<li>Read_Weights 将weight从内存中读取到TPU的 Weight FIFO 上.</li>
<li>MatrixMultiply/Convolve 执行卷积或矩阵乘法操作.</li>
<li>Activate 执行人工神经网络中的非线性操作和Pooling操作（如有）</li>
<li>Write_Host_Memory 将结果从Unified Buffer写回CPU内存.</li>
</ul>
<p>从给出的五条指令可以看出，TPU的指令集设计和通用处理器有很大的不同。指令需要显示指定数据在内存和片上buffer之间搬移的过程。而执行指令（MatrixMultiply）直接指定了Buffer的地址，指令上并不能看到一系列通用寄存器。这是因为TPU本质上还是一个专用的处理芯片，其高性能和高效能都是建立在失去一定灵活性的前提下的。为了获得更高的性能，可以采用一系列的常规方法进行设计，包括</p>
<ul>
<li>指令并行，即一次性处理更多指令，让所有执行单元高效运行</li>
<li>数据并行，即一次性处理多组数据，提高性能</li>
</ul>
<p>后文会针对这两点做进一步描述，并简单讨论TPU设计中的更多其他的优化方法和方向。</p>
<h1 id="2-指令并行"><a href="#2-指令并行" class="headerlink" title="2. 指令并行"></a>2. 指令并行</h1><h2 id="2-1-Simple-TPU中的流水线"><a href="#2-1-Simple-TPU中的流水线" class="headerlink" title="2.1 Simple TPU中的流水线"></a>2.1 Simple TPU中的流水线</h2><p>为了提高吞吐率和时钟频率，处理器通常使用流水线设计，经典的五级流水线设计一般如下所示</p>
<table>
<thead>
<tr>
<th></th>
<th>clk0</th>
<th>clk1</th>
<th>clk2</th>
<th>clk3</th>
<th>clk4</th>
<th>clk5</th>
<th>clk6</th>
<th>clk7</th>
</tr>
</thead>
<tbody><tr>
<td>instruction0</td>
<td>IF</td>
<td>ID</td>
<td>EX</td>
<td>MEM</td>
<td>WB</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>instruction1</td>
<td></td>
<td>IF</td>
<td>ID</td>
<td>EX</td>
<td>MEM</td>
<td>WB</td>
<td></td>
<td></td>
</tr>
<tr>
<td>instruction2</td>
<td></td>
<td></td>
<td>IF</td>
<td>ID</td>
<td>EX</td>
<td>MEM</td>
<td>WB</td>
<td></td>
</tr>
<tr>
<td>instruction3</td>
<td></td>
<td></td>
<td></td>
<td>IF</td>
<td>ID</td>
<td>EX</td>
<td>MEM</td>
<td>WB</td>
</tr>
</tbody></table>
<p>其中，IF指取指(insturction fetch)，ID指指令译码（instruction decode），EX指执行（Execute），MEM指内存读写（Memory Access），WB指写回寄存器(Write back)。采用流水线设计可以提高性能，如果不采用流水线设计，那么instruction1需要在clk5才能开始进行IF，严重影响其性能；如果在同一周期完成IF/ID/EX/MEM/WB的功能，由于逻辑极其复杂，会严重影响工作频率。</p>
<p>TPU论文中介绍其采用四级流水线设计，Simple TPU中采用了两级流水线，来完成控制过程。</p>
<table>
<thead>
<tr>
<th></th>
<th>clk0</th>
<th>clk1</th>
<th>clk2</th>
<th>clk3</th>
<th>clk4</th>
<th>clk5</th>
<th>clk6</th>
<th>clk7</th>
</tr>
</thead>
<tbody><tr>
<td>instruction0</td>
<td>IF&amp;ID</td>
<td>EX</td>
<td>MEM</td>
<td>WB</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>instruction1</td>
<td></td>
<td>IF&amp;ID</td>
<td>EX</td>
<td>MEM</td>
<td>WB</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>instruction2</td>
<td></td>
<td></td>
<td>IF&amp;ID</td>
<td>EX</td>
<td>MEM</td>
<td>WB</td>
<td></td>
<td></td>
</tr>
<tr>
<td>instruction3</td>
<td></td>
<td></td>
<td></td>
<td>IF&amp;ID</td>
<td>EX</td>
<td>MEM</td>
<td>WB</td>
<td></td>
</tr>
</tbody></table>
<p>也认为Simple TPU内部有四级流水线，这是因为在实际执行过程中，包括了读取寄存器，执行和写回三个部分，这三个部分是流水设计的。</p>
<h2 id="2-2-超长指令字（VLIW）"><a href="#2-2-超长指令字（VLIW）" class="headerlink" title="2.2 超长指令字（VLIW）"></a>2.2 超长指令字（VLIW）</h2><p>如前文所述，Simple TPU中有两个基本的计算单元——矩阵乘法阵列和池化计算单元。除此之外，还有一些没有显式描述的执行单元，譬如载入和存储。在这一前提下，即使TPU的指令流水线做得再好，每条指令占有的周期数也不可能小于1。如果其他执行单元的执行周期数很小，此时总会有一些执行单元处于闲置状态，处理器的瓶颈会出现在指令上。为了解决这一问题，很直接的想法时每个周期发射多条指令（另一个方法时让执行单元的执行时间变长，Simple TPU通过向量体系结构设计也有这一处理）。</p>
<p>由于TPU的专用性，以及计算过程中不存在跳转和控制的原因，采用VLIW设计多发射处理器似乎是一个很适合的方式。在这一设计下，指令发射结构时固定的，而且所有的冒险可以由编译器事先检测并处理，这很大程度可以降低硬件实现的复杂度。在Simple TPU中借鉴了VLIW的思想进行设计，如下所示(示意图)</p>
<p><img src="https://raw.githubusercontent.com/cea-wind/blogs_pictures/master/img20190803171553.png" alt></p>
<p>其中各个字段具体描述如下</p>
<ul>
<li>model mask 指定了当前指令运行的模块</li>
<li>load weight 指定了从内存将weight读取到SRAM的指令</li>
<li>load act. &amp; mac &amp; store result 指定了将操作数（act.）读取到寄存器，乘加阵列计算以及将结果写回到存储器的过程</li>
<li>set weight 指定了将操作数（weight）读取到计算阵列寄存器的过程</li>
<li>load act. &amp; pooling&amp; store result field指定了将操作数（act.）读取到寄存器，完成pooling和归一化计算以及将结果写回到存储器的过程</li>
</ul>
<p>VLIW的设计放弃了很多的灵活性和兼容性，同时将很多工作放到软件完成，但依旧适合在TPU这样的偏专用的处理器中使用。Simple TPU中没有对数据冲突、依赖进行任何处理，软件需要事先完成分析并进行规避。在这一设计下一条指令可以调度最多四个模块同时工作，效率得到了提升。</p>
<h1 id="3-卷积计算中的数据并行"><a href="#3-卷积计算中的数据并行" class="headerlink" title="3. 卷积计算中的数据并行"></a>3. 卷积计算中的数据并行</h1><h2 id="3-1-单指令多数据（SIMD）"><a href="#3-1-单指令多数据（SIMD）" class="headerlink" title="3.1 单指令多数据（SIMD）"></a>3.1 单指令多数据（SIMD）</h2><p>单指令多数据，故名思意是指在一条指令控制多组数据的计算。显然，TPU core的设计中采用了这样一种数据并行的方式——一条instruction控制了256*256个乘加计算单元（MatirxMultiply/Convolve）。根据指令流和数据流之间的对应关系，可以将处理器分为以下几个类别</p>
<ul>
<li>SISD，单指令流单数据流，顺序执行指令，处理数据，可以应用指令并行方法</li>
<li>SIMD，单指令流多数据流，同一指令启动多组数据运算，可以用于开发数据级并行</li>
<li>MISD，多指令流单数据流，暂无商业实现</li>
<li>MIMD，多指令流多数据流，每个处理器用各种的指令对各自的数据进行操作，可以用在任务级并行上，也可用于数据级并行，比SIMD更灵活</li>
</ul>
<p>由于TPU应用在规则的矩阵/卷积计算中，在单个处理器内部的设计上，SIMD是数据并行的最优选择。SIMD有多种实现方式，根据给出的描述（MatirxMultiply/Convolve指令接受B<em>256输入，输出B</em>256个结果），TPU中应该采用了类似向量体系结构的设计方法。</p>
<h2 id="3-2-向量体系结构"><a href="#3-2-向量体系结构" class="headerlink" title="3.2 向量体系结构"></a>3.2 向量体系结构</h2><p>如基本单元-矩阵乘法阵列所述，计算单元完成矩阵乘法计算，即向量计算。以《计算机体系结构 : 量化研究方法》给出的例子为例，如需计算</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for(int i=0;i&lt;N;i++)</span><br><span class="line">    y[i] += a*x[i];</span><br></pre></td></tr></table></figure>

<p>以MIPS为例，对于一般的标量处理器和向量处理器而言，执行的指令序列如下所示</p>
<p><img src="https://raw.githubusercontent.com/cea-wind/blogs_pictures/master/img20190803171640.png" alt></p>
<p>对于卷积神经网络中的卷积操作而言，计算可以表示为（已忽略bias）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">for(int i=0;i&lt;M;i++)&#123;</span><br><span class="line">    for(int j=0;j&lt;N;j++)&#123;</span><br><span class="line">        for(int k=0;k&lt;K;k++)&#123;</span><br><span class="line">            for(int c=0;c&lt;C;c++)&#123;</span><br><span class="line">                for(int kw=0;kw&lt;KW;kw++)&#123;</span><br><span class="line">                    for(int kh=0;kh&lt;KH;kh++)&#123;</span><br><span class="line">                        result(i,j,k) += feature(i+kw,j+kh,c)*w(k,kw,kh,c);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>由于KW和KH可能为1（即卷积核的宽度和高度），而weight在计算过程中认为是固定在计算阵列内部的，因此调整循环顺序后有</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">for(int kw=0;kw&lt;KW;kw++)&#123;</span><br><span class="line">    for(int kh=0;kh&lt;KH;kh++)&#123;</span><br><span class="line">        for(int k=0;k&lt;K;k++)&#123;</span><br><span class="line">            for(int i=0;i&lt;M;i++)&#123;</span><br><span class="line">                for(int j=0;j&lt;N;j++)&#123;</span><br><span class="line">                    for(int c=0;c&lt;C;c++)&#123;</span><br><span class="line">                        result(i,j,k) += feature(i+kw,j+kh,c)*w(k,kw,kh,c);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其中第一二层循环通过指令进行控制，第三层循环在计算阵列中以256并行度进行计算，指令调度；第4-6层循环按向量处理器的设计思路进行设计，通过一条指令完成三层循环的计算。为了完成循环的计算，需要设置三个向量长度寄存器，另外，由于向量在SRAM中的地址并不连续，还需要设定三个不同的步幅寄存器。参考 基本单元-矩阵乘法阵列的代码，具体为</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">short ubuf_raddr_step1;</span><br><span class="line">short ubuf_raddr_step2;</span><br><span class="line">short ubuf_raddr_step3;</span><br><span class="line">short ubuf_raddr_end1;</span><br><span class="line">short ubuf_raddr_end2;</span><br><span class="line">short ubuf_raddr_end3</span><br></pre></td></tr></table></figure>

<p> 采用这样的设计，SimpleTPU中一条指令可以完成大量数据的计算，提高了数据并行度。这些数据会并行的进入到计算阵列中完成计算（可以认为是多条车道）。由于SimpleTPU中数据的读取延时是固定的（指从SRAM），因此向量化的设计较一般处理器还更为简单。</p>
<p>根据谷歌论文中的描述，TPU中有repeat fileld，但MatrixMultiply/Convolve指令长度有限，因此可能只有一组或两组向量长度寄存器和步幅寄存器，但设计思路应该类似。</p>
<h1 id="4-其他"><a href="#4-其他" class="headerlink" title="4. 其他"></a>4. 其他</h1><p>从谷歌论文中的参数来看，TPU具有极高单位功耗下性能。这一部分来自于其内核设计，正如之前的文章中所描述的</p>
<ul>
<li>采用了INT8数据类型进行计算</li>
<li>采用了脉动阵列优化计算</li>
<li>没有采用缓存，没有分支跳转，预测和数据冲突处理（编译器完成）</li>
</ul>
<p>而从本文的内容可以看出，TPU还采用了简单的指令集设计+SIMD+向量体系结构+VLIW来进一步优化单位功耗下性能；除此之外，在V2/V3中google更进一步，还利用多核和多处理器设计进一步提高了性能。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>[1] Jouppi, Norman P. , et al. “In-Datacenter Performance Analysis of a Tensor Processing Unit.” the 44th Annual International Symposium IEEE Computer Society, 2017.<br>[2] JohnL.Hennessy, and DavidA.Patterson. Computer architecture : a quantitative approach = 计算机体系结构 : 量化研究方法/ 5th ed.</p>

    </div>

    
    
    

    <footer class="post-footer">
          
        
        <div class="post-tags">
            <a href="/tags/Tensor-Processing-Unit/" rel="tag"># Tensor Processing Unit</a>
          
            <a href="/tags/Architecture/" rel="tag"># Architecture</a>
          
            <a href="/tags/Instruction-Level-Parallelism/" rel="tag"># Instruction Level Parallelism</a>
          
            <a href="/tags/Data-Parallelism/" rel="tag"># Data Parallelism</a>
          
            <a href="/tags/VLIW/" rel="tag"># VLIW</a>
          
            <a href="/tags/SMID/" rel="tag"># SMID</a>
          
            <a href="/tags/Vector-Architecture/" rel="tag"># Vector Architecture</a>
          
        </div>
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
              <a href="/2019/08/03/TPU_c3/" rel="next" title="神经网络中的归一化和池化的硬件实现">
                <i class="fa fa-chevron-left"></i> 神经网络中的归一化和池化的硬件实现
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
              <a href="/2019/08/03/TPU_c5/" rel="prev" title="Simple TPU的设计和性能评估">
                Simple TPU的设计和性能评估 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
    </footer>
  </div>
  
  
  
  </article>

  </div>


          </div>
          


        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">

          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name"></p>
  <div class="site-description motion-element" itemprop="description"></div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">7</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        
        
          
        
          
        
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">分类</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">标签</span>
        </a>
      </div>
    
  </nav>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="https://github.com/cea-wind" title="GitHub &rarr; https://github.com/cea-wind" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
    
  </div>



        </div>
      </div>
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-TPU的指令集"><span class="nav-text">1. TPU的指令集</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-指令并行"><span class="nav-text">2. 指令并行</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-Simple-TPU中的流水线"><span class="nav-text">2.1 Simple TPU中的流水线</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-超长指令字（VLIW）"><span class="nav-text">2.2 超长指令字（VLIW）</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-卷积计算中的数据并行"><span class="nav-text">3. 卷积计算中的数据并行</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-单指令多数据（SIMD）"><span class="nav-text">3.1 单指令多数据（SIMD）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-向量体系结构"><span class="nav-text">3.2 向量体系结构</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-其他"><span class="nav-text">4. 其他</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#参考"><span class="nav-text">参考</span></a></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder"></span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.3.0</div>

        








        
      </div>
    </footer>
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
      </div>

    

  </div>

  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  <script src="/js/utils.js?v=7.3.0"></script>
  <script src="/js/motion.js?v=7.3.0"></script>

  
  <script src="/js/affix.js?v=7.3.0"></script>
  <script src="/js/schemes/pisces.js?v=7.3.0"></script>


  
  <script src="/js/scrollspy.js?v=7.3.0"></script>
<script src="/js/post-details.js?v=7.3.0"></script>



  <script src="/js/next-boot.js?v=7.3.0"></script>

  

  

  


  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>



  
































</body>
</html>

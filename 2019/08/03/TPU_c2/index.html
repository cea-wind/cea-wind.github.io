<!DOCTYPE html>





<html class="theme-next pisces use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="generator" content="Hexo 3.9.0">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.3.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.3.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.3.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '7.3.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    search: {
      root: '/',
      path: ''
    },
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    }
  };
</script>

  <meta name="description" content="深度学习飞速发展过程中，人们发现原有的处理器无法满足神经网络这种特定的大量计算，大量的开始针对这一应用进行专用芯片的设计。谷歌的张量处理单元（Tensor Processing Unit，后文简称TPU）是完成较早，具有代表性的一类设计，基于脉动阵列设计的矩阵计算加速单元，可以很好的加速神经网络的计算。本系列文章将利用公开的TPU V1相关资料，对其进行一定的简化、推测和修改，来实际编写一个简单">
<meta name="keywords" content="Tensor Processing Unit,Systolic Array">
<meta property="og:type" content="article">
<meta property="og:title" content="TPU中的脉动阵列及其实现">
<meta property="og:url" content="http://cea-wind.github.io/2019/08/03/TPU_c2/index.html">
<meta property="og:site_name" content="SEAWIND">
<meta property="og:description" content="深度学习飞速发展过程中，人们发现原有的处理器无法满足神经网络这种特定的大量计算，大量的开始针对这一应用进行专用芯片的设计。谷歌的张量处理单元（Tensor Processing Unit，后文简称TPU）是完成较早，具有代表性的一类设计，基于脉动阵列设计的矩阵计算加速单元，可以很好的加速神经网络的计算。本系列文章将利用公开的TPU V1相关资料，对其进行一定的简化、推测和修改，来实际编写一个简单">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://raw.githubusercontent.com/cea-wind/blogs_pictures/master/img20190803171231.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cea-wind/blogs_pictures/master/img20190803171259.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cea-wind/blogs_pictures/master/img20190803171343.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cea-wind/blogs_pictures/master/img20190803171414.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cea-wind/blogs_pictures/master/img20190803160407.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cea-wind/blogs_pictures/master/img20190803160443.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cea-wind/blogs_pictures/master/img20190803160454.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cea-wind/blogs_pictures/master/img20190803171137.png">
<meta property="og:image" content="https://raw.githubusercontent.com/cea-wind/blogs_pictures/master/img20190803160349.png">
<meta property="og:updated_time" content="2019-08-03T09:14:20.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="TPU中的脉动阵列及其实现">
<meta name="twitter:description" content="深度学习飞速发展过程中，人们发现原有的处理器无法满足神经网络这种特定的大量计算，大量的开始针对这一应用进行专用芯片的设计。谷歌的张量处理单元（Tensor Processing Unit，后文简称TPU）是完成较早，具有代表性的一类设计，基于脉动阵列设计的矩阵计算加速单元，可以很好的加速神经网络的计算。本系列文章将利用公开的TPU V1相关资料，对其进行一定的简化、推测和修改，来实际编写一个简单">
<meta name="twitter:image" content="https://raw.githubusercontent.com/cea-wind/blogs_pictures/master/img20190803171231.png">
  <link rel="canonical" href="http://cea-wind.github.io/2019/08/03/TPU_c2/">


<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>TPU中的脉动阵列及其实现 | SEAWIND</title>
  








  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">SEAWIND</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
    <ul id="menu" class="menu">
        
        
        
          
          <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">
      
    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
    </ul>
</nav>

</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://cea-wind.github.io/2019/08/03/TPU_c2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SEAWIND">
    </span>
      <header class="post-header">

        
          <h2 class="post-title" itemprop="name headline">TPU中的脉动阵列及其实现

              
            
          </h2>
        

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-08-03 00:17:00 / 修改时间：17:14:20" itemprop="dateCreated datePublished" datetime="2019-08-03T00:17:00+08:00">2019-08-03</time>
            </span>
          
            

            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/TPU/" itemprop="url" rel="index"><span itemprop="name">TPU</span></a></span>

                
                
              
            </span>
          

          <br>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <blockquote>
<p>深度学习飞速发展过程中，人们发现原有的处理器无法满足神经网络这种特定的大量计算，大量的开始针对这一应用进行专用芯片的设计。谷歌的张量处理单元（Tensor Processing Unit，后文简称TPU）是完成较早，具有代表性的一类设计，基于脉动阵列设计的矩阵计算加速单元，可以很好的加速神经网络的计算。本系列文章将利用公开的TPU V1相关资料，对其进行一定的简化、推测和修改，来实际编写一个简单版本的谷歌TPU，以更确切的了解TPU的优势和局限性。</p>
</blockquote>
<p>本文将对TPU中的矩阵计算单元进行分析，并给出了SimpleTPU中32×32的脉动阵列的实现方式和采用该阵列进行卷积计算的方法，以及一个卷积的设计实例，验证了其正确性。代码地址<a href="https://github.com/cea-wind/SimpleTPU/tree/master/lab1" target="_blank" rel="noopener">https://github.com/cea-wind/SimpleTPU/tree/master/lab1</a></p>
<h1 id="1-脉动阵列和矩阵计算"><a href="#1-脉动阵列和矩阵计算" class="headerlink" title="1. 脉动阵列和矩阵计算"></a>1. 脉动阵列和矩阵计算</h1><p> 脉动阵列是一种复用输入数据的设计，对于TPU中的二维脉动阵列，很多文章中构造了脉动阵列的寄存器模型，导致阅读较为困难，而实际上TPU中的二维脉动阵列设计思路十分直接。譬如当使用4×4的脉动阵列计算4×4的矩阵乘法时，有</p>
<p>$$ A\times B = \begin{bmatrix}<br>1 &amp; 1 &amp; 1 &amp; 1\ <br>2 &amp; 2 &amp; 2 &amp; 2\ <br>3 &amp; 3 &amp; 3 &amp; 3\ <br>4 &amp; 4 &amp; 4 &amp; 4<br>\end{bmatrix} \times \begin{bmatrix}<br> 1 &amp; 5 &amp; 9  &amp;13 \ <br> 2 &amp; 6 &amp; 10 &amp;14 \ <br> 3 &amp; 7 &amp; 11 &amp;15 \ <br> 4 &amp; 8 &amp; 12 &amp;16<br>\end{bmatrix} = \begin{bmatrix}<br> 10&amp; 26 &amp; 42  &amp;58 \ <br> 20&amp; 52 &amp; 84  &amp;116 \ <br> 30&amp; 78 &amp; 126 &amp;174 \ <br> 40&amp; 104&amp; 168 &amp;232<br>\end{bmatrix}$$</p>
<p><img src="https://raw.githubusercontent.com/cea-wind/blogs_pictures/master/img20190803171231.png" alt></p>
<p>如上图所示，右侧是一个乘加单元的内部结构，其内部有一个寄存器，在TPU内对应存储Weight，此处存储矩阵B。左图是一个4×4的乘加阵列，假设矩阵B已经被加载到乘加阵列内部；显然，乘加阵列中每一列计算四个数的乘法并将其加在一起，即得到矩阵乘法的一个输出结果。依次输入矩阵A的四行，可以得到矩阵乘法的结果。</p>
<p>由于硬件上的限制，需要对传播路径上添加寄存器，而添加寄存器相对于在第i个时刻处理的内容变成了i+1时刻处理；这一过程可以进行计算结果上的等效。如下图所示，采用z-1代表添加一个延时为1的寄存器，如果在纵向的psum传递路径上添加寄存器，为了保证结果正确，需要在横向的输入端也添加一个寄存器（即原本在i进行乘加计算的两个数均在i+1时刻进行计算）。给纵向每个psum路径添加寄存器后，输入端处理如右图所示。（下图仅考虑第一列的处理）</p>
<p><img src="https://raw.githubusercontent.com/cea-wind/blogs_pictures/master/img20190803171259.png" alt></p>
<p>当在横向的数据路径上添加寄存器时，只要每一列都添加相同延时，那么计算结果会是正确的，但是结果会在后一个周期输出，如下图所示</p>
<p><img src="https://raw.githubusercontent.com/cea-wind/blogs_pictures/master/img20190803171343.png" alt></p>
<p>上述分析可以，一个4×4的乘加阵列可以计算一组4×4的乘加阵列完成计算，而对于其他维度的乘法，则可以通过多次调用的方式完成计算。譬如（4×4）×（4×8），可以将（4×8）的乘法拆分乘两个4×4的矩阵乘；而对于（4×8）×（8×4），两个矩阵计算完成后还需要将其结果累加起来，这也是为何TPU在乘加阵列后需要添加Accumulators的原因。最终脉动阵列设计如下所示（以4×4为例）</p>
<p><img src="https://raw.githubusercontent.com/cea-wind/blogs_pictures/master/img20190803171414.png" alt></p>
<h1 id="2-脉动阵列的实现"><a href="#2-脉动阵列的实现" class="headerlink" title="2. 脉动阵列的实现"></a>2. 脉动阵列的实现</h1><p>如第一节所述，可通过HLS构建一个脉动阵列并进行仿真。类似TPU中的设计，采用INT8作为计算阵列的输入数据类型，为防止计算过程中的溢出，中间累加结果采用INT32存储。由于INT32的表示范围远高于INT8，认为计算过程中不存在上溢的可能性，因此没有对溢出进行处理。脉动阵列的计算结果数据类型为INT32，会在后文进行下一步处理。</p>
<p>脉动阵列实现的关键代码包括</p>
<ol>
<li>Feature向右侧移动</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">for(int j=0;j&lt;MXU_ROWNUM;j++)&#123;</span><br><span class="line">    for(int k=MXU_ROWNUM+MXU_COLNUM-2;k&gt;=0;k--)&#123;</span><br><span class="line">        if(k&gt;0)</span><br><span class="line">            featreg[j][k] = featreg[j][k-1];</span><br><span class="line">        else</span><br><span class="line">            if(i&lt;mxuparam.ubuf_raddr_num)</span><br><span class="line">                featreg[j][k] = ubuf[ubuf_raddr][j];</span><br><span class="line">            else</span><br><span class="line">                featreg[j][k] = 0;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>乘法计算以及向下方移动的psum</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">for(int j=MXU_ROWNUM-1;j&gt;=0;j--)&#123;</span><br><span class="line">    for(int k=0;k&lt;MXU_COLNUM;k++)&#123;</span><br><span class="line">        ap_int&lt;32&gt; biasreg;</span><br><span class="line">        biasreg(31,24)=weightreg[MXU_ROWNUM+0][k];</span><br><span class="line">        biasreg(23,16)=weightreg[MXU_ROWNUM+1][k];</span><br><span class="line">        biasreg(15, 8)=weightreg[MXU_ROWNUM+2][k];</span><br><span class="line">        biasreg( 7, 0)=weightreg[MXU_ROWNUM+3][k];</span><br><span class="line">        if(j==0)</span><br><span class="line">            psumreg[j][k] = featreg[j][k+j]*weightreg[j][k] + biasreg;</span><br><span class="line">        else</span><br><span class="line">            psumreg[j][k] = featreg[j][k+j]*weightreg[j][k] + psumreg[j-1][k];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>完成代码编写后可进行行为级仿真，可以看出整个计算阵列的时延关系</p>
<ol>
<li>对于同一列而言，下一行的输入比上一行晚一个周期<br><img src="https://raw.githubusercontent.com/cea-wind/blogs_pictures/master/img20190803160407.png" alt></li>
<li>对于同一行而言，下一列的输入比上一列晚一个周期（注意同一行输入数据是一样的）<br><img src="https://raw.githubusercontent.com/cea-wind/blogs_pictures/master/img20190803160443.png" alt></li>
<li>下一列的输出结果比上一列晚一个周期<br><img src="https://raw.githubusercontent.com/cea-wind/blogs_pictures/master/img20190803160454.png" alt></li>
</ol>
<h1 id="3-从矩阵乘法到三维卷积"><a href="#3-从矩阵乘法到三维卷积" class="headerlink" title="3. 从矩阵乘法到三维卷积"></a>3. 从矩阵乘法到三维卷积</h1><p>卷积神经网络计算过程中，利用kh×kw×C的卷积核和H×W×C的featuremap进行乘加计算。以3×3卷积为例，如下图所示，省略Channel方向，拆分kh和kw方向分别和featuremap进行卷积，可以得到9个输出结果，这9个输出结果按照一定规律加在一起，就可以得到追后的卷积计算结果。下图给出了3×3卷积，padding=2时的计算示意图。按F1-F9给9个矩阵乘法结果编号，输出featuremap中点（2，1）——指第二行第一个点——是F1（1，1），F2（1，2），F3（1，3），F4（2，1），F5（2，2），F6（2，3），F7（3，1），F8（3，2），F9（3，3）的和。</p>
<p><img src="https://raw.githubusercontent.com/cea-wind/blogs_pictures/master/img20190803171137.png" alt></p>
<p>下面的MATLAB代码阐明了这种计算三维卷积的方式，9个结果错位相加的MATLAB代码如下所示</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">output = out1;</span><br><span class="line">output(2:end,2:end,:) = output(2:end,2:end,:) + out2(1:end-1,1:end-1,:);</span><br><span class="line">output(2:end,:,:) = output(2:end,:,:) + out3(1:end-1,:,:);</span><br><span class="line">output(2:end,1:end-1,:) = output(2:end,1:end-1,:) + out4(1:end-1,2:end,:);</span><br><span class="line">output(:,2:end,:) = output(:,2:end,:) + out5(:,1:end-1,:);</span><br><span class="line">output(:,1:end-1,:) = output(:,1:end-1,:) + out6(:,2:end,:);</span><br><span class="line">output(1:end-1,2:end,:) = output(1:end-1,2:end,:) + out7(2:end,1:end-1,:);</span><br><span class="line">output(1:end-1,:,:) = output(1:end-1,:,:) + out8(2:end,:,:);</span><br><span class="line">output(1:end-1,1:end-1,:) = output(1:end-1,1:end-1,:) + out9(2:end,2:end,:);</span><br></pre></td></tr></table></figure>

<p>而在实际的HLS代码以及硬件实现上，部分未使用的值并未计算，因此实际计算的index和上述示意图并不相同，具体可参考testbench中的配置方法。</p>
<h1 id="4-其他"><a href="#4-其他" class="headerlink" title="4. 其他"></a>4. 其他</h1><p>GPU的volta架构中引入了Tensor Core来计算4×4的矩阵乘法，由于4×4的阵列规模较小，其内部可能并没有寄存器，设计可能类似第一节图1所示。由于其平均一个周期就能完成4×4矩阵计算，猜测采用第一节中阵列进行堆叠，如下图所示。</p>
<p><img src="https://raw.githubusercontent.com/cea-wind/blogs_pictures/master/img20190803160349.png" alt></p>
<p>一些FPGA加速库中利用脉动阵列实现了矩阵乘法，不过不同与TPU中将一个输入固定在MAC内部，还可以选择将psum固定在MAC内部，而两个输入都是时刻在变化的。这几种方式是类似的，就不再展开描述了。</p>

    </div>

    
    
    

    <footer class="post-footer">
          
        
        <div class="post-tags">
            <a href="/tags/Tensor-Processing-Unit/" rel="tag"># Tensor Processing Unit</a>
          
            <a href="/tags/Systolic-Array/" rel="tag"># Systolic Array</a>
          
        </div>
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
              <a href="/2019/08/02/TPU_c1/" rel="next" title="动手写一个简单版的谷歌TPU">
                <i class="fa fa-chevron-left"></i> 动手写一个简单版的谷歌TPU
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
              <a href="/2019/08/03/TPU_c3/" rel="prev" title="神经网络中的归一化和池化的硬件实现">
                神经网络中的归一化和池化的硬件实现 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
    </footer>
  </div>
  
  
  
  </article>

  </div>


          </div>
          


        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">

          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name"></p>
  <div class="site-description motion-element" itemprop="description"></div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">7</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        
        
          
        
          
        
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">分类</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">标签</span>
        </a>
      </div>
    
  </nav>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="https://github.com/cea-wind" title="GitHub &rarr; https://github.com/cea-wind" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
    
  </div>



        </div>
      </div>
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-脉动阵列和矩阵计算"><span class="nav-text">1. 脉动阵列和矩阵计算</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-脉动阵列的实现"><span class="nav-text">2. 脉动阵列的实现</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-从矩阵乘法到三维卷积"><span class="nav-text">3. 从矩阵乘法到三维卷积</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-其他"><span class="nav-text">4. 其他</span></a></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder"></span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.3.0</div>

        








        
      </div>
    </footer>
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
      </div>

    

  </div>

  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  <script src="/js/utils.js?v=7.3.0"></script>
  <script src="/js/motion.js?v=7.3.0"></script>

  
  <script src="/js/affix.js?v=7.3.0"></script>
  <script src="/js/schemes/pisces.js?v=7.3.0"></script>


  
  <script src="/js/scrollspy.js?v=7.3.0"></script>
<script src="/js/post-details.js?v=7.3.0"></script>



  <script src="/js/next-boot.js?v=7.3.0"></script>

  

  

  


  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>



  
    
      <script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  
































</body>
</html>
